---
title: "BME4550_Datapalooza"
author: "Kelsie Reinaltt"
date: "11/22/2018"
output: html_document
---

The workshop I attended at Datapalooza, a convention “sponsored” by the Data Science Institute, was lead by Professor Janet and Dr. Samuel Lengen, focused on the relational ethics and humanness of data. To commence the workshop on ethics, Dr. Lengen begins to address the two different ways of approaching an ethics question: by rules or by relationships. An interpretive, relationship-focused approach, following a rulebook or checklist is not the priority. When taking a relational ethics approach to data science and analysis, the idea is to think of data as connected to people’s lives and not just “raw data”. 

Just because data is presented as a raw resource does not mean we should not question how and when the data was gathered. Data comes from prior sets of interpretations, and therefore it is important to consider how data is collected and the methodology of analysis. Any kinds of biases in data collection or analysis are grounds for a claim to be made that the data is  “not raw”. When performing his own data analysis, Dr. Lengen considers the following questions: Who/what was collected? With what precision?

One example of how data was used in an unethical and biased way was in the small city of Reading, Pennsylvania. In 2011, Reading had the highest poverty rate in the country at 41.3% as a result of the 2008 market crash. As a result of the recession, 45 officers were cut from the police force in Reading. The Chief Police Officer, William Heim, invested in PredPol crime prediction software in order to figure out how to effectively police the small city with the reduced number of manpower. Jeffrey Brantingham, the founder of PredPol stressed that the crime prediction software was “blind to race and ethnicity” and instead “targets geography”. The program processed historical crime data and calculated where crimes were most likely to occur hour by hour. Based on the results of the software, more of the force would spend time patrolling the areas flagged by the software with the goal of discouraging crime in that area. After a year, the Chief Police claimed that burglaries were down by 23%. Although the results and words of founder Brantingham seem promising, this paper will continue to discuss the results, flaws, and solutions to crime predicting software.

The PredPol system has two options for crimes police can focus on: type one crimes, which are violent crimes, including homicide and assault, and type two crimes, which are selling/consuming small quantities of drugs, and panhandling. The type two crimes are native to impoverished neighborhoods and skews the results of analysis, thus drawing more police to these neighborhoods where they’re more likely to arrest more people. The data will then integrate these police interactions into their dataset, inevitably continuing a cruel feedback loop. As discussed in the workshop, “the policing itself spawns new data, which justifies more policing. And our prisons fill up with hundreds of thousands of people… most of them [coming] from impoverished neighborhoods, and most are Black and Hispanic”. Therefore, although Bartinghame claims his model is “color blind”, the result the police acting on the data from the model is anything but color blind. In largely segregated cities, discrimination of race can often be reflected in geography. 

The phenomenon of antisocial behavior and crime being seen as linked is well explained by public policy expert James Q. Wilson by a concept called broken-windows policing. The die is that low-level crimes create an atmosphere of disorder in a neighborhood, scaring law-abiding citizens away. With less people in the area, the streets become a breeding ground for more serious crime and more alarmed citizens leaving the locality. To counteract this adversity, society must resist the spread of disorder and take steps to discourage nuisance crimes.

Something to take into consideration with regards to PredPol and other criminal predictive software is that it prioritizes crimes such as homicide, repe, and assult, then shoplifting, fraud, and parking violations - but what about white collar crimes? There is no reason to believe that street crime is more prevalent than white collar crime. If police enforced the zero-tolerance strategy in finance as they do for any other crime and social setting, the amount of white middle-class and wealthy men incarcerated would increase significantly. The probability that police would begin to take more action on white-collar crimes however is quite unlikely - the tools and skill required to crack down on financial crimes are completely different from the expertise of the majority of cops. 

Although PredPol  and other crime prediction tools were created with the intention to be useful and “high-minded” software tool, PredPol prompts police to zero in on the poor, stopping more of of them , and thus sending  a subgroup to prison. To rephrase and recap in a direct and concise manner, by using this skewed “raw” data,  we are criminalizing poverty. 

I found this workshop to be very enlightening and thought evoking. The most remarkable lesson I have taken away from this workshop is to question everything for you own good and the good of others; all datasets should be received with some kind of credibility and/or explanation. Personally, I took this advice to question everything as something that could not only be applied to data science and analysis, but in my own life as well, which made this workshop even more fascinating to me. 
